**Facial Expression Recognition Model**

With the ever-increasing computational powers and much refined deep learning models and the availability of data sets on social media platforms, emotion detection technology is touching newer milestones.Furthermore, the presence of data in the form of videos, audios, images leads to an excellent scope for emotion detection technologies to show their tremendous capabilities.According to a market research report by Markets and Markets, the Emotion recognition market size is projected to grow from USD 19.5 billion in 2020 to USD 37.1 billion by 2026, at a Compound Annual Growth Rate (CAGR) of 11.3%.

We are Future Co ,Data Analysis company ,that create a model to assist predicting users'facial expression.

Team members: Terry, Jane, Mary, Eric and Nato

Project Goal: 
Create Machine Learning Model to analyze people’s faces (pictures) to see how a person is feeling.


Use of the model: Different use cases are like:
    Market research: moment-by-moment facial expressions and emotions (facial coding) automatically vs verbal Surveys
    Safe and personalized cars:Drivers Facial Expression
    Virtual  Assistances: siri and Alex Facial Expression
    Video games testing
    Gamers real time FER
    Law enforcement, surveillance, and monitoring
    Children Safety and surveillance :At Schools and Daycares
    Marketing, advertising, media, entertainment, and PR(Public Relations):Retail,Malls
    More in-depth interviews:HR


Data: Used Kaggle.com (https://www.kaggle.com/datasets/debanga/facial-expression-recognition-challenge?select=fer2013.tar)

Dataset has 48x48 pixel greyscale images of faces. With 7 different categories with set of 28709 examples (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). Which reduced to detect only "Happy" or "Sad". 

The dataset was prepared by Pierre-Luc Carrier and Aaron Courville.

The model is able to scan the people’s faces in 48x48 pixel images and read how the person is feeling at that moment ("Happy" or "Sad").

The model used Pandas, Matplotlib.

The model has:

Three trained models. The most accurate Model is "Model A" with 95% accuracy. 

Limitation: The person’s facial expression could be different depending on unique type. The model is running only based on the dataset. The team members are not experts in facial or emotions.


Fun Finding: Is Mona Lisa happy or sad?

Fun Fact: Based on Facial Expression Recognition Model - MONA LISA is "SAD"!!!


References:
Data source: Kaggle.com
(https://www.kaggle.com/datasets/debanga/facial-expression-recognition-challenge?select=fer2013.tar)
Real-time emotion recognition: Potential use cases and challenges ,Article
https://indiaai.gov.in/article/real-time-emotion-recognition-potential-use-cases-and-challenges

